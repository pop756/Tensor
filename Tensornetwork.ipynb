{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-21 11:38:27.940582: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-21 11:38:28.399206: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensornetwork as tn\n",
    "import numpy as np\n",
    "import tensornetwork as tn\n",
    "class TNLayer(tf.keras.layers.Layer):\n",
    " \n",
    "  def __init__(self,Tensor_dimention = 20):\n",
    "    super(TNLayer, self).__init__()\n",
    "    # Create the variables for the layer.\n",
    "    \n",
    "\n",
    "    self.A1 = tf.Variable(tf.random.normal(shape=[4,Tensor_dimention,8], stddev=1.0/256.0),name=\"a1\", trainable=True)\n",
    "    self.A2 = tf.Variable(tf.random.normal(shape=[4,Tensor_dimention,Tensor_dimention,4], stddev=1.0/256.0),name=\"a2\", trainable=True)\n",
    "    self.A3 = tf.Variable(tf.random.normal(shape=[4,Tensor_dimention,Tensor_dimention,4], stddev=1.0/256.0),name=\"a3\", trainable=True)\n",
    "    self.A4 = tf.Variable(tf.random.normal(shape=[4,Tensor_dimention,12], stddev=1.0/256.0),name=\"a4\", trainable=True)\n",
    "\n",
    "    self.bias = tf.Variable(tf.zeros(shape=(256*6)), name=\"bias\", trainable=True)\n",
    " \n",
    "  def call(self, inputs):\n",
    "    # Define the contraction.\n",
    "    # We break it out so we can parallelize a batch using\n",
    "    # tf.vectorized_map (see below).\n",
    "    Nodes = [tn.Node(self.A1,'a0',backend=\"tensorflow\")]\n",
    "    Nodes+=[tn.Node(self.A2,f'a{1}',backend=\"tensorflow\")]\n",
    "    Nodes+=[tn.Node(self.A3,f'a{2}',backend=\"tensorflow\")]\n",
    "    Nodes+=[tn.Node(self.A4,f'a{3}',backend=\"tensorflow\")]\n",
    "    def f(input_vec, Nodes, bias_var):\n",
    "      # Reshape to a matrix instead of a vector.\n",
    "      input_vec = tf.reshape(input_vec, [200,4,4,4,4])\n",
    "      T_node = tn.Node(input_vec, backend=\"tensorflow\",name = 't')\n",
    "      for i in range(len(Nodes)-1):\n",
    "          if i == 0:\n",
    "              Nodes[i][1]^Nodes[i+1][1]\n",
    "          else:\n",
    "              Nodes[i][2]^Nodes[i+1][1]\n",
    "\n",
    "      for i in range(len(Nodes)):\n",
    "          if i == 0 or i == (len(Nodes))-1:\n",
    "              Nodes[i][0]^T_node[i+1]\n",
    "          else:\n",
    "              Nodes[i][3]^T_node[i+1]\n",
    "      A = tn.to_graphviz(Nodes+[T_node])     \n",
    "      contraction = T_node@Nodes[0]\n",
    "      for i in range(1,len(Nodes)):\n",
    "        contraction = contraction@Nodes[i]\n",
    "      result = tf.reshape(contraction.tensor,[200,256*6])\n",
    "\n",
    "      # To make the code shorter, we also could've used Ncon.\n",
    "      # The above few lines of code is the same as this:\n",
    "      # result = tn.ncon([x, a_var, b_var], [[1, 2], [-1, 1, 3], [-2, 2, 3]])\n",
    " \n",
    "      # Finally, add bias.\n",
    "      return result + bias_var\n",
    "  \n",
    "    # To deal with a batch of items, we can use the tf.vectorized_map\n",
    "    # function.\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/vectorized_map\n",
    "    result = tf.vectorized_map(\n",
    "        lambda vec: f(vec, Nodes, self.bias), inputs)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-21 11:38:28.999731: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-21 11:38:29.017150: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-21 11:38:29.017288: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-21 11:38:29.018471: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-21 11:38:29.018581: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-21 11:38:29.018677: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-21 11:38:29.060082: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-21 11:38:29.060216: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-21 11:38:29.060319: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-21 11:38:29.060403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21434 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:09:00.0, compute capability: 8.6\n",
      "2023-12-21 11:38:29.325498: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 200, 1536), dtype=float32, numpy=\n",
       "array([[[-3.65314662e-07, -1.49800996e-07,  5.95339316e-07, ...,\n",
       "         -1.28110244e-07,  2.79519895e-07,  4.38398331e-07],\n",
       "        [ 2.65480196e-07,  1.62413130e-07, -8.12657674e-07, ...,\n",
       "          3.55212592e-07,  4.50027244e-07, -7.89342067e-08],\n",
       "        [ 3.94209508e-07,  1.02907200e-06,  4.47108192e-07, ...,\n",
       "         -1.26556301e-07, -3.06222375e-07, -4.84874704e-07],\n",
       "        ...,\n",
       "        [-5.50077004e-07, -4.33651678e-07,  1.42126709e-07, ...,\n",
       "         -1.87102785e-07,  1.48502437e-08, -5.01837690e-07],\n",
       "        [-6.09619178e-07, -9.85340193e-07, -1.16776243e-06, ...,\n",
       "         -3.01511164e-07, -4.48813580e-07,  5.16206171e-08],\n",
       "        [ 5.77559831e-07, -6.32321303e-07,  8.43774160e-07, ...,\n",
       "          5.54238227e-07, -1.59658399e-07,  4.03335108e-08]],\n",
       "\n",
       "       [[-3.90378830e-07, -1.06017062e-07, -4.90865318e-07, ...,\n",
       "          1.91617460e-07,  2.38905109e-08,  3.00571486e-07],\n",
       "        [ 5.14403609e-07, -7.55888223e-08, -2.74192558e-07, ...,\n",
       "         -4.74567798e-07, -3.03095007e-08,  3.98624906e-07],\n",
       "        [ 6.53246104e-07,  1.62429188e-07, -2.45118571e-07, ...,\n",
       "          3.22557696e-07,  1.53162603e-07,  1.03889313e-07],\n",
       "        ...,\n",
       "        [ 1.02620099e-08, -5.26318786e-07,  5.49721904e-08, ...,\n",
       "          2.51388684e-07, -5.48259095e-07, -4.23106279e-08],\n",
       "        [-4.38633919e-07,  1.56187809e-07, -3.19267514e-07, ...,\n",
       "          4.44709599e-07, -5.64016432e-07,  2.15982908e-07],\n",
       "        [-6.09618212e-07, -1.01569434e-07,  3.03913026e-07, ...,\n",
       "          4.02600818e-07, -2.60519613e-07, -7.39278860e-09]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = TNLayer()\n",
    "temp(tf.random.normal([2,200,256]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class MultiheadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads,classical_rate = 0.25,Tensor_dimention = 20):\n",
    "        super(MultiheadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "        self.num_heads = num_heads\n",
    "        self.depth = d_model\n",
    "        self.rate = classical_rate\n",
    "        assert int(num_heads/classical_rate) == num_heads/classical_rate\n",
    "\n",
    "\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(int(d_model)*int(num_heads*classical_rate))\n",
    "        self.wk = tf.keras.layers.Dense(int(d_model)*int(num_heads*classical_rate))\n",
    "        self.wv = tf.keras.layers.Dense(int(d_model)*int(num_heads*classical_rate))\n",
    "\n",
    "        self.wq_tensor = TNLayer(Tensor_dimention)\n",
    "        self.wk_tensor = TNLayer(Tensor_dimention)\n",
    "        self.wv_tensor = TNLayer(Tensor_dimention)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, int(self.num_heads*self.rate), self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    def split_heads_tensor(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, int(self.num_heads*(1-self.rate)), self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    def call(self, q, k, v, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        \n",
    "        print(q.shape)\n",
    "        q_class = self.split_heads(self.wq(q), batch_size)\n",
    "        k_class = self.split_heads(self.wk(k), batch_size)\n",
    "        v_class = self.split_heads(self.wv(v), batch_size)\n",
    "        print(q_class.shape)\n",
    "        q_tensor = self.split_heads_tensor(self.wq_tensor(q),batch_size)\n",
    "        k_tensor = self.split_heads_tensor(self.wq_tensor(k),batch_size)\n",
    "        v_tensor = self.split_heads_tensor(self.wq_tensor(v),batch_size)\n",
    "        print(q_tensor.shape)\n",
    "        q,k,v = tf.concat([q_class,q_tensor],axis=1),tf.concat([k_class,k_tensor],axis=1),tf.concat([v_class,v_tensor],axis=1)\n",
    "\n",
    "        scaled_attention, attention_weights = self.scaled_dot_product_attention(q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.depth*self.num_heads))\n",
    "\n",
    "        output = self.dense(concat_attention)\n",
    "        return output, attention_weights\n",
    "\n",
    "    def scaled_dot_product_attention(self, q, k, v, mask):\n",
    "        matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "        dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "        scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "        if mask is not None:\n",
    "            scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "        output = tf.matmul(attention_weights, v)\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 200, 256)\n",
      "(None, 2, None, 256)\n",
      "(None, 6, None, 256)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 200, 256)]   0           []                               \n",
      "                                                                                                  \n",
      " multihead_attention (Multihead  ((None, None, 256),  967104     ['input_1[0][0]',                \n",
      " Attention)                      (None, 8, None, No               'input_1[0][0]',                \n",
      "                                ne))                              'input_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 967,104\n",
      "Trainable params: 967,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input = tf.keras.layers.Input([200,256])\n",
    "output,_ = MultiheadAttention(256,8)(input,input,input,None)\n",
    "output = output\n",
    "model = tf.keras.Model(inputs  = [input], outputs = [output])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 200, 256)\n",
      "(256, 2, 200, 256)\n",
      "(256, 6, 200, 256)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 200, 256), dtype=float32, numpy=\n",
       "array([[[-3.73702450e-03, -2.06267834e-02, -6.05356656e-02, ...,\n",
       "          4.13719714e-02, -3.59384567e-02,  1.32235205e-02],\n",
       "        [-1.19590359e-02, -3.89066688e-03, -3.07100173e-02, ...,\n",
       "          7.09708631e-02, -4.08575051e-02,  4.52038087e-02],\n",
       "        [-3.86949293e-02, -5.45938537e-02, -1.76048763e-02, ...,\n",
       "          8.40343069e-03,  9.62884910e-03,  3.09624784e-02],\n",
       "        ...,\n",
       "        [-4.61964235e-02, -4.60500792e-02,  2.37633586e-02, ...,\n",
       "          8.43577459e-02, -1.05146300e-02,  4.80099656e-02],\n",
       "        [-1.54572548e-02, -6.22609109e-02, -2.05411986e-02, ...,\n",
       "          2.13305112e-02, -2.25147698e-02,  4.18667644e-02],\n",
       "        [ 3.44831198e-02, -6.64576516e-02, -1.21740317e-02, ...,\n",
       "          2.87348609e-02, -8.75886306e-02,  3.03424243e-02]],\n",
       "\n",
       "       [[-3.27780060e-02,  6.54790029e-02, -2.71975864e-02, ...,\n",
       "          1.53236426e-02,  3.67707200e-02, -4.15575178e-03],\n",
       "        [ 5.81410117e-02,  1.28691187e-02,  3.43106091e-02, ...,\n",
       "          8.68338645e-02, -3.05294637e-02, -1.05565330e-02],\n",
       "        [ 2.69340362e-05,  2.37074643e-02, -3.20085534e-03, ...,\n",
       "          5.50487898e-02,  1.93003584e-02, -5.34094721e-02],\n",
       "        ...,\n",
       "        [ 1.45009961e-02,  6.94187433e-02, -3.65663469e-02, ...,\n",
       "          1.44437822e-02,  3.90586816e-02,  4.69578356e-02],\n",
       "        [ 1.01411585e-02,  7.50481188e-02,  2.64154375e-02, ...,\n",
       "          1.03906460e-01,  4.81170928e-03,  2.49060504e-02],\n",
       "        [-3.55957858e-02,  1.07429527e-01, -1.92218572e-02, ...,\n",
       "          3.92349288e-02,  6.50966913e-02,  4.84839566e-02]],\n",
       "\n",
       "       [[ 2.53144689e-02, -5.23693711e-02,  5.01901396e-02, ...,\n",
       "         -1.96890682e-02, -8.55450034e-02,  5.36990277e-02],\n",
       "        [-5.58902025e-02,  9.23366994e-02,  8.81742761e-02, ...,\n",
       "         -3.36525328e-02, -1.15750909e-01,  1.07742637e-01],\n",
       "        [-6.23521022e-03,  3.90245691e-02, -5.08761853e-02, ...,\n",
       "          3.10132653e-03, -1.20720066e-01,  7.73337558e-02],\n",
       "        ...,\n",
       "        [ 6.59391582e-02, -2.04559322e-02,  5.30020744e-02, ...,\n",
       "         -3.08930892e-02, -8.75313431e-02,  5.67808151e-02],\n",
       "        [ 3.33600752e-02,  1.76324379e-02,  4.09724303e-02, ...,\n",
       "         -1.08915186e-02, -1.12901352e-01,  7.94327632e-02],\n",
       "        [ 1.94288976e-02, -4.50498844e-03,  1.90179478e-02, ...,\n",
       "         -4.94379140e-02, -7.12171718e-02,  1.42234161e-01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 1.53387086e-02,  1.50130340e-03, -5.63215511e-03, ...,\n",
       "          1.21274851e-02, -2.82917265e-02, -1.07179463e-01],\n",
       "        [ 6.41474575e-02,  3.74726765e-02,  1.25163384e-02, ...,\n",
       "          3.28840092e-02, -2.83382945e-02, -2.69342326e-02],\n",
       "        [ 3.48398313e-02, -1.46348132e-02,  3.30033079e-02, ...,\n",
       "         -2.48860214e-02, -5.88001162e-02, -6.31080270e-02],\n",
       "        ...,\n",
       "        [ 2.57825945e-03,  4.19099070e-02, -6.20849840e-02, ...,\n",
       "         -3.90361398e-02, -3.94382887e-02, -6.15884922e-03],\n",
       "        [ 1.24884555e-02,  3.22058564e-03,  2.30167294e-03, ...,\n",
       "          6.87359646e-02,  3.64682148e-03, -4.99793887e-02],\n",
       "        [-4.48057055e-02,  1.20135350e-02, -3.08119860e-02, ...,\n",
       "         -9.11451783e-03, -7.54419621e-03,  1.43278316e-02]],\n",
       "\n",
       "       [[-1.58255529e-02,  5.44872358e-02, -8.72531626e-03, ...,\n",
       "          1.44887539e-02, -1.02240033e-02,  7.29465187e-02],\n",
       "        [-2.29573026e-02, -9.40805487e-03, -1.63720530e-02, ...,\n",
       "          2.53771637e-02,  8.38474557e-02,  3.30441706e-02],\n",
       "        [ 5.29079884e-02, -2.89695188e-02,  7.66507909e-03, ...,\n",
       "          5.22971526e-02,  3.69307511e-02,  1.09820388e-01],\n",
       "        ...,\n",
       "        [-5.19668758e-02, -2.30121259e-02, -1.96902175e-02, ...,\n",
       "          2.18597166e-02, -4.38197702e-02,  3.67614776e-02],\n",
       "        [ 1.16848079e-02, -1.46600325e-02, -5.78657119e-03, ...,\n",
       "         -5.02310041e-03,  2.86131781e-02,  1.13824211e-01],\n",
       "        [-5.43056205e-02,  5.00068553e-02,  2.85310354e-02, ...,\n",
       "          4.50961888e-02, -5.07534258e-02,  4.48555239e-02]],\n",
       "\n",
       "       [[ 3.05812247e-02,  6.33833883e-03,  6.36686757e-02, ...,\n",
       "          3.60353626e-02,  6.80292547e-02,  2.33462825e-02],\n",
       "        [ 6.84248731e-02, -2.90713478e-02,  4.57248427e-02, ...,\n",
       "          6.78605735e-02,  7.41679445e-02, -4.71715890e-02],\n",
       "        [ 4.75574583e-02, -3.24460492e-02,  2.44025490e-03, ...,\n",
       "          2.85221599e-02,  9.81072262e-02,  4.46994007e-02],\n",
       "        ...,\n",
       "        [ 2.53387988e-02,  6.90678880e-02,  1.53765501e-02, ...,\n",
       "         -1.62797477e-02,  1.04752854e-01,  1.90691184e-02],\n",
       "        [ 8.33065063e-02,  1.83462491e-03,  1.35659315e-02, ...,\n",
       "          8.86088759e-02,  9.76762921e-02, -2.93703303e-02],\n",
       "        [ 6.37877882e-02, -3.77527326e-02,  1.25115693e-01, ...,\n",
       "          3.99554260e-02,  7.06394166e-02,  1.69204865e-02]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(tf.random.normal([256,200,256]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, embedding_dim, num_heads=8):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.embedding_dim = embedding_dim # d_model\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        assert embedding_dim % self.num_heads == 0\n",
    "\n",
    "        self.projection_dim = embedding_dim\n",
    "        self.query_dense = tf.keras.layers.Dense(embedding_dim*num_heads)\n",
    "        self.key_dense = tf.keras.layers.Dense(embedding_dim*num_heads)\n",
    "        self.value_dense = tf.keras.layers.Dense(embedding_dim*num_heads)\n",
    "        self.dense = tf.keras.layers.Dense(embedding_dim)\n",
    "\n",
    "    def scaled_dot_product_attention(self, query, key, value):\n",
    "        matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "        depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        logits = matmul_qk / tf.math.sqrt(depth)\n",
    "        attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "        output = tf.matmul(attention_weights, value)\n",
    "        return output, attention_weights\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "\n",
    "        # (batch_size, seq_len, embedding_dim)\n",
    "        query = self.query_dense(inputs)\n",
    "        key = self.key_dense(inputs)\n",
    "        value = self.value_dense(inputs)\n",
    "\n",
    "        # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        query = self.split_heads(query, batch_size)  \n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "        print(query)\n",
    "        scaled_attention, _ = self.scaled_dot_product_attention(query, key, value)\n",
    "        print(scaled_attention.shape)\n",
    "        # (batch_size, seq_len, num_heads, projection_dim)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  \n",
    "\n",
    "        # (batch_size, seq_len, embedding_dim)\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.embedding_dim*num_heads))\n",
    "        outputs = self.dense(concat_attention)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"multi_head_attention_60/transpose:0\", shape=(32, 8, 200, 256), dtype=float32)\n",
      "(32, 8, 200, 256)\n"
     ]
    }
   ],
   "source": [
    "input = tf.keras.layers.Input([200,256],batch_size=32)\n",
    "output = MultiHeadAttention(256,8)(input)\n",
    "model = tf.keras.Model(inputs  = [input], outputs = [output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_56\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_72 (InputLayer)       [(32, 200, 256)]          0         \n",
      "                                                                 \n",
      " multi_head_attention_60 (Mu  (32, 200, 256)           2103552   \n",
      " ltiHeadAttention)                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,103,552\n",
      "Trainable params: 2,103,552\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 200, 256)\n",
      "(32, 4, 200, 16)\n"
     ]
    }
   ],
   "source": [
    "input = tf.keras.layers.Input([200,256],batch_size=32)\n",
    "output,_ =  MultiheadAttention(256,16)(input,input,input,None)\n",
    "\n",
    "model = tf.keras.Model(inputs  = [input], outputs = [output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(32, 200, 256) dtype=float32 (created by layer 'multihead_attention_11')>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_47\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_60 (InputLayer)          [(32, 200, 256)]     0           []                               \n",
      "                                                                                                  \n",
      " multihead_attention_11 (Multih  ((32, 200, 256),    155792      ['input_60[0][0]',               \n",
      " eadAttention)                   (32, 16, 200, 200)               'input_60[0][0]',               \n",
      "                                )                                 'input_60[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 155,792\n",
      "Trainable params: 155,792\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 200, 256), dtype=float32, numpy=\n",
       "array([[[-0.7576784 ,  0.5117144 ,  1.3913641 , ...,  1.569271  ,\n",
       "         -1.1123393 ,  0.88063514],\n",
       "        [-0.4770038 ,  0.149418  , -1.6568892 , ...,  0.24261492,\n",
       "         -0.3732225 , -0.92699033],\n",
       "        [-0.93850803,  0.9730366 ,  0.20917985, ...,  0.29123157,\n",
       "         -0.25967714,  1.2175975 ],\n",
       "        ...,\n",
       "        [ 1.7240776 , -0.39755765,  1.0520613 , ...,  0.11004458,\n",
       "          1.0479846 ,  0.4702791 ],\n",
       "        [-0.31224385, -0.1991196 , -0.25010037, ..., -0.78511393,\n",
       "          0.2746125 ,  0.08908027],\n",
       "        [ 0.37627482,  0.6397044 ,  0.39135456, ...,  0.52852196,\n",
       "         -0.5584524 ,  0.23717976]]], dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(tf.random.normal([1,200,256]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN = TNLayer()\n",
    "A = np.random.random([200,256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 11:49:18.616703: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 200, 192), dtype=float32, numpy=\n",
       "array([[[ 3.9458379e-07, -3.0122372e-08, -4.7138479e-07, ...,\n",
       "          1.6917920e-06, -2.0015385e-07, -4.3961748e-07],\n",
       "        [ 1.5410170e-07, -3.6303497e-08, -3.7850884e-07, ...,\n",
       "          8.8086756e-07,  3.2530153e-07,  2.0509961e-07],\n",
       "        [-3.6292690e-07,  3.0433881e-07, -7.1985124e-07, ...,\n",
       "          1.1278707e-06,  1.3492263e-07,  2.0843441e-07],\n",
       "        ...,\n",
       "        [ 1.1674189e-08,  1.3615391e-07, -8.3924039e-07, ...,\n",
       "          8.6666080e-07, -7.7096711e-09, -3.6934164e-08],\n",
       "        [-2.1719433e-07, -9.0083233e-08, -4.3829752e-07, ...,\n",
       "          1.1408886e-06,  3.2110330e-09,  1.1046866e-07],\n",
       "        [-2.3101596e-07, -9.6460667e-08, -5.1828181e-07, ...,\n",
       "          7.0417246e-07,  2.7571778e-07, -6.1455154e-07]],\n",
       "\n",
       "       [[ 3.9458379e-07, -3.0122372e-08, -4.7138479e-07, ...,\n",
       "          1.6917920e-06, -2.0015385e-07, -4.3961748e-07],\n",
       "        [ 1.5410170e-07, -3.6303497e-08, -3.7850884e-07, ...,\n",
       "          8.8086756e-07,  3.2530153e-07,  2.0509961e-07],\n",
       "        [-3.6292690e-07,  3.0433881e-07, -7.1985124e-07, ...,\n",
       "          1.1278707e-06,  1.3492263e-07,  2.0843441e-07],\n",
       "        ...,\n",
       "        [ 1.1674189e-08,  1.3615391e-07, -8.3924039e-07, ...,\n",
       "          8.6666080e-07, -7.7096711e-09, -3.6934164e-08],\n",
       "        [-2.1719433e-07, -9.0083233e-08, -4.3829752e-07, ...,\n",
       "          1.1408886e-06,  3.2110330e-09,  1.1046866e-07],\n",
       "        [-2.3101596e-07, -9.6460667e-08, -5.1828181e-07, ...,\n",
       "          7.0417246e-07,  2.7571778e-07, -6.1455154e-07]],\n",
       "\n",
       "       [[ 3.9458379e-07, -3.0122372e-08, -4.7138479e-07, ...,\n",
       "          1.6917920e-06, -2.0015385e-07, -4.3961748e-07],\n",
       "        [ 1.5410170e-07, -3.6303497e-08, -3.7850884e-07, ...,\n",
       "          8.8086756e-07,  3.2530153e-07,  2.0509961e-07],\n",
       "        [-3.6292690e-07,  3.0433881e-07, -7.1985124e-07, ...,\n",
       "          1.1278707e-06,  1.3492263e-07,  2.0843441e-07],\n",
       "        ...,\n",
       "        [ 1.1674189e-08,  1.3615391e-07, -8.3924039e-07, ...,\n",
       "          8.6666080e-07, -7.7096711e-09, -3.6934164e-08],\n",
       "        [-2.1719433e-07, -9.0083233e-08, -4.3829752e-07, ...,\n",
       "          1.1408886e-06,  3.2110330e-09,  1.1046866e-07],\n",
       "        [-2.3101596e-07, -9.6460667e-08, -5.1828181e-07, ...,\n",
       "          7.0417246e-07,  2.7571778e-07, -6.1455154e-07]],\n",
       "\n",
       "       [[ 3.9458379e-07, -3.0122372e-08, -4.7138479e-07, ...,\n",
       "          1.6917920e-06, -2.0015385e-07, -4.3961748e-07],\n",
       "        [ 1.5410170e-07, -3.6303497e-08, -3.7850884e-07, ...,\n",
       "          8.8086756e-07,  3.2530153e-07,  2.0509961e-07],\n",
       "        [-3.6292690e-07,  3.0433881e-07, -7.1985124e-07, ...,\n",
       "          1.1278707e-06,  1.3492263e-07,  2.0843441e-07],\n",
       "        ...,\n",
       "        [ 1.1674189e-08,  1.3615391e-07, -8.3924039e-07, ...,\n",
       "          8.6666080e-07, -7.7096711e-09, -3.6934164e-08],\n",
       "        [-2.1719433e-07, -9.0083233e-08, -4.3829752e-07, ...,\n",
       "          1.1408886e-06,  3.2110330e-09,  1.1046866e-07],\n",
       "        [-2.3101596e-07, -9.6460667e-08, -5.1828181e-07, ...,\n",
       "          7.0417246e-07,  2.7571778e-07, -6.1455154e-07]],\n",
       "\n",
       "       [[ 3.9458379e-07, -3.0122372e-08, -4.7138479e-07, ...,\n",
       "          1.6917920e-06, -2.0015385e-07, -4.3961748e-07],\n",
       "        [ 1.5410170e-07, -3.6303497e-08, -3.7850884e-07, ...,\n",
       "          8.8086756e-07,  3.2530153e-07,  2.0509961e-07],\n",
       "        [-3.6292690e-07,  3.0433881e-07, -7.1985124e-07, ...,\n",
       "          1.1278707e-06,  1.3492263e-07,  2.0843441e-07],\n",
       "        ...,\n",
       "        [ 1.1674189e-08,  1.3615391e-07, -8.3924039e-07, ...,\n",
       "          8.6666080e-07, -7.7096711e-09, -3.6934164e-08],\n",
       "        [-2.1719433e-07, -9.0083233e-08, -4.3829752e-07, ...,\n",
       "          1.1408886e-06,  3.2110330e-09,  1.1046866e-07],\n",
       "        [-2.3101596e-07, -9.6460667e-08, -5.1828181e-07, ...,\n",
       "          7.0417246e-07,  2.7571778e-07, -6.1455154e-07]]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TN(np.array([A,A,A,A,A]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 11:49:29.730378: W tensorflow/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 400.00MiB (rounded to 419430400)requested by op AddV2\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-12-20 11:49:29.730412: I tensorflow/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2023-12-20 11:49:29.730424: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 4, Chunks in use: 4. 1.0KiB allocated for chunks. 1.0KiB in use in bin. 16B client-requested in use in bin.\n",
      "2023-12-20 11:49:29.730432: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 6, Chunks in use: 5. 4.5KiB allocated for chunks. 3.8KiB in use in bin. 3.6KiB client-requested in use in bin.\n",
      "2023-12-20 11:49:29.730439: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 8, Chunks in use: 8. 8.5KiB allocated for chunks. 8.5KiB in use in bin. 7.5KiB client-requested in use in bin.\n",
      "2023-12-20 11:49:29.730445: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-20 11:49:29.730451: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-20 11:49:29.730458: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 7, Chunks in use: 5. 96.2KiB allocated for chunks. 71.2KiB in use in bin. 70.3KiB client-requested in use in bin.\n",
      "2023-12-20 11:49:29.730465: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 4, Chunks in use: 3. 95.0KiB allocated for chunks. 68.5KiB in use in bin. 64.1KiB client-requested in use in bin.\n",
      "2023-12-20 11:49:29.730470: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-20 11:49:29.730476: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-20 11:49:29.730481: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-20 11:49:29.730487: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-20 11:49:29.730494: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 1, Chunks in use: 1. 750.0KiB allocated for chunks. 750.0KiB in use in bin. 750.0KiB client-requested in use in bin.\n",
      "2023-12-20 11:49:29.730499: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-20 11:49:29.730505: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 1, Chunks in use: 0. 2.83MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-20 11:49:29.730511: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-20 11:49:29.730516: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-20 11:49:29.730522: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-20 11:49:29.730527: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-20 11:49:29.730533: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-20 11:49:29.730541: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 1, Chunks in use: 0. 128.67MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-20 11:49:29.730548: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 2, Chunks in use: 2. 800.00MiB allocated for chunks. 800.00MiB in use in bin. 800.00MiB client-requested in use in bin.\n",
      "2023-12-20 11:49:29.730554: I tensorflow/tsl/framework/bfc_allocator.cc:1062] Bin for 400.00MiB was 256.00MiB, Chunk State: \n",
      "2023-12-20 11:49:29.730559: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 977731584\n",
      "2023-12-20 11:49:29.730567: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100000000 of size 1280 next 1\n",
      "2023-12-20 11:49:29.730572: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100000500 of size 256 next 2\n",
      "2023-12-20 11:49:29.730577: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100000600 of size 256 next 3\n",
      "2023-12-20 11:49:29.730582: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100000700 of size 256 next 4\n",
      "2023-12-20 11:49:29.730587: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100000800 of size 768 next 11\n",
      "2023-12-20 11:49:29.730592: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100000b00 of size 768 next 17\n",
      "2023-12-20 11:49:29.730596: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100000e00 of size 768 next 5\n",
      "2023-12-20 11:49:29.730601: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100001100 of size 1280 next 6\n",
      "2023-12-20 11:49:29.730606: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100001600 of size 1024 next 10\n",
      "2023-12-20 11:49:29.730611: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100001a00 of size 1024 next 12\n",
      "2023-12-20 11:49:29.730616: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100001e00 of size 1024 next 16\n",
      "2023-12-20 11:49:29.730621: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100002200 of size 1024 next 19\n",
      "2023-12-20 11:49:29.730627: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100002600 of size 1024 next 20\n",
      "2023-12-20 11:49:29.730632: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f4100002a00 of size 27136 next 15\n",
      "2023-12-20 11:49:29.730637: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100009400 of size 18944 next 7\n",
      "2023-12-20 11:49:29.730643: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f410000de00 of size 25600 next 8\n",
      "2023-12-20 11:49:29.730648: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100014200 of size 25600 next 9\n",
      "2023-12-20 11:49:29.730653: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f410001a600 of size 14592 next 18\n",
      "2023-12-20 11:49:29.730658: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f410001df00 of size 768 next 24\n",
      "2023-12-20 11:49:29.730662: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f410001e200 of size 256 next 31\n",
      "2023-12-20 11:49:29.730667: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f410001e300 of size 768 next 25\n",
      "2023-12-20 11:49:29.730672: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f410001e600 of size 1024 next 26\n",
      "2023-12-20 11:49:29.730676: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f410001ea00 of size 768 next 30\n",
      "2023-12-20 11:49:29.730681: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f410001ed00 of size 11008 next 21\n",
      "2023-12-20 11:49:29.730686: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100021800 of size 14592 next 22\n",
      "2023-12-20 11:49:29.730690: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100025100 of size 14592 next 23\n",
      "2023-12-20 11:49:29.730695: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f4100028a00 of size 14592 next 27\n",
      "2023-12-20 11:49:29.730701: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f410002c300 of size 14592 next 28\n",
      "2023-12-20 11:49:29.730706: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f410002fc00 of size 14592 next 29\n",
      "2023-12-20 11:49:29.730721: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f4100033500 of size 2969856 next 13\n",
      "2023-12-20 11:49:29.730730: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100308600 of size 768000 next 14\n",
      "2023-12-20 11:49:29.730739: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f41003c3e00 of size 419430400 next 32\n",
      "2023-12-20 11:49:29.730749: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f41193c3e00 of size 419430400 next 33\n",
      "2023-12-20 11:49:29.730758: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f41323c3e00 of size 134922752 next 18446744073709551615\n",
      "2023-12-20 11:49:29.730767: I tensorflow/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2023-12-20 11:49:29.730775: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 256 totalling 1.0KiB\n",
      "2023-12-20 11:49:29.730781: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 5 Chunks of size 768 totalling 3.8KiB\n",
      "2023-12-20 11:49:29.730786: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 1024 totalling 6.0KiB\n",
      "2023-12-20 11:49:29.730791: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 1280 totalling 2.5KiB\n",
      "2023-12-20 11:49:29.730797: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 5 Chunks of size 14592 totalling 71.2KiB\n",
      "2023-12-20 11:49:29.730802: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 18944 totalling 18.5KiB\n",
      "2023-12-20 11:49:29.730808: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 25600 totalling 50.0KiB\n",
      "2023-12-20 11:49:29.730813: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 768000 totalling 750.0KiB\n",
      "2023-12-20 11:49:29.730819: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 419430400 totalling 800.00MiB\n",
      "2023-12-20 11:49:29.730824: I tensorflow/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 800.88MiB\n",
      "2023-12-20 11:49:29.730830: I tensorflow/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 977731584 memory_limit_: 977731584 available bytes: 0 curr_region_allocation_bytes_: 1955463168\n",
      "2023-12-20 11:49:29.730839: I tensorflow/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                       977731584\n",
      "InUse:                       839785472\n",
      "MaxInUse:                    839785472\n",
      "NumAllocs:                          71\n",
      "MaxAllocSize:                419430400\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-12-20 11:49:29.730846: W tensorflow/tsl/framework/bfc_allocator.cc:497] ***************************************************************************************_____________\n",
      "2023-12-20 11:49:29.730868: W tensorflow/core/framework/op_kernel.cc:1818] RESOURCE_EXHAUSTED: failed to allocate memory\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "pybind11::error_already_set: MISMATCH of original and normalized active exception types: ORIGINAL _NotOkStatusException REPLACED BY KeyboardInterrupt: <EMPTY MESSAGE>\n\nAt:\n  /home/yslee/.local/lib/python3.8/site-packages/tensorflow/python/eager/core.py(36): __init__\n  /home/yslee/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py(461): add_v2\n  /home/yslee/.local/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py(4022): add\n  /home/yslee/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py(1176): op_dispatch_handler\n  /home/yslee/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py(150): error_handler\n  /home/yslee/.local/lib/python3.8/site-packages/tensorflow/python/ops/random_ops.py(94): random_normal\n  /home/yslee/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py(1176): op_dispatch_handler\n  /home/yslee/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py(150): error_handler\n  /tmp/ipykernel_237025/2652562775.py(70): <module>\n  /home/yslee/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3508): run_code\n  /home/yslee/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3448): run_ast_nodes\n  /home/yslee/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3269): run_cell_async\n  /home/yslee/.local/lib/python3.8/site-packages/IPython/core/async_helpers.py(129): _pseudo_sync_runner\n  /home/yslee/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3064): _run_cell\n  /home/yslee/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3009): run_cell\n  /home/yslee/.local/lib/python3.8/site-packages/ipykernel/zmqshell.py(549): run_cell\n  /home/yslee/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py(429): do_execute\n  /home/yslee/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py(766): execute_request\n  /home/yslee/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py(424): dispatch_shell\n  /home/yslee/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py(518): process_one\n  /home/yslee/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py(529): dispatch_queue\n  /usr/lib/python3.8/asyncio/events.py(81): _run\n  /usr/lib/python3.8/asyncio/base_events.py(1859): _run_once\n  /usr/lib/python3.8/asyncio/base_events.py(570): run_forever\n  /home/yslee/.local/lib/python3.8/site-packages/tornado/platform/asyncio.py(205): start\n  /home/yslee/.local/lib/python3.8/site-packages/ipykernel/kernelapp.py(739): start\n  /home/yslee/.local/lib/python3.8/site-packages/traitlets/config/application.py(1077): launch_instance\n  /home/yslee/.local/lib/python3.8/site-packages/ipykernel_launcher.py(17): <module>\n  /usr/lib/python3.8/runpy.py(87): _run_code\n  /usr/lib/python3.8/runpy.py(194): _run_module_as_main\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_237025/2652562775.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mMultiheadAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclassical_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTensor_dimention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    463\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m       return add_v2_eager_fallback(\n\u001b[1;32m    470\u001b[0m           x, y, name=name, ctx=_ctx)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: pybind11::error_already_set: MISMATCH of original and normalized active exception types: ORIGINAL _NotOkStatusException REPLACED BY KeyboardInterrupt: <EMPTY MESSAGE>\n\nAt:\n  /home/yslee/.local/lib/python3.8/site-packages/tensorflow/python/eager/core.py(36): __init__\n  /home/yslee/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py(461): add_v2\n  /home/yslee/.local/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py(4022): add\n  /home/yslee/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py(1176): op_dispatch_handler\n  /home/yslee/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py(150): error_handler\n  /home/yslee/.local/lib/python3.8/site-packages/tensorflow/python/ops/random_ops.py(94): random_normal\n  /home/yslee/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py(1176): op_dispatch_handler\n  /home/yslee/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py(150): error_handler\n  /tmp/ipykernel_237025/2652562775.py(70): <module>\n  /home/yslee/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3508): run_code\n  /home/yslee/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3448): run_ast_nodes\n  /home/yslee/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3269): run_cell_async\n  /home/yslee/.local/lib/python3.8/site-packages/IPython/core/async_helpers.py(129): _pseudo_sync_runner\n  /home/yslee/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3064): _run_cell\n  /home/yslee/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3009): run_cell\n  /home/yslee/.local/lib/python3.8/site-packages/ipykernel/zmqshell.py(549): run_cell\n  /home/yslee/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py(429): do_execute\n  /home/yslee/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py(766): execute_request\n  /home/yslee/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py(424): dispatch_shell\n  /home/yslee/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py(518): process_one\n  /home/yslee/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py(529): dispatch_queue\n  /usr/lib/python3.8/asyncio/events.py(81): _run\n  /usr/lib/python3.8/asyncio/base_events.py(1859): _run_once\n  /usr/lib/python3.8/asyncio/base_events.py(570): run_forever\n  /home/yslee/.local/lib/python3.8/site-packages/tornado/platform/asyncio.py(205): start\n  /home/yslee/.local/lib/python3.8/site-packages/ipykernel/kernelapp.py(739): start\n  /home/yslee/.local/lib/python3.8/site-packages/traitlets/config/application.py(1077): launch_instance\n  /home/yslee/.local/lib/python3.8/site-packages/ipykernel_launcher.py(17): <module>\n  /usr/lib/python3.8/runpy.py(87): _run_code\n  /usr/lib/python3.8/runpy.py(194): _run_module_as_main\n"
     ]
    }
   ],
   "source": [
    "MultiheadAttention\n",
    "\n",
    "# \n",
    "d_model = 256\n",
    "num_heads = 8\n",
    "input_seq_len = 200\n",
    "batch_size = 2048\n",
    "\n",
    "multihead_attention = MultiheadAttention(d_model, num_heads,Tensor_dimention=15)\n",
    "input_q = tf.random.normal((batch_size, input_seq_len, d_model))\n",
    "input_k = tf.random.normal((batch_size, input_seq_len, d_model))\n",
    "input_v = tf.random.normal((batch_size, input_seq_len, d_model))\n",
    "mask = None  # Optional mask to specify which positions should be masked\n",
    "output, attention_weights = multihead_attention(input_q, input_k, input_v, mask)\n",
    "print(\"Multihead Attention Output shape:\", output.shape)\n",
    "print(\"Attention Weights shape:\", attention_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 200, 256), dtype=float32, numpy=\n",
       "array([[[-0.4862139 ,  0.96792114,  0.42404115, ...,  0.09001559,\n",
       "          0.46600857, -1.0089929 ],\n",
       "        [-0.62987536, -2.5237682 , -0.35136494, ...,  0.6651539 ,\n",
       "          0.5311567 , -0.04648928],\n",
       "        [ 0.3532162 , -0.49647188, -1.1656084 , ...,  0.29334262,\n",
       "          0.0310472 , -0.9394325 ],\n",
       "        ...,\n",
       "        [ 0.0506833 ,  1.1525031 ,  1.6949191 , ...,  0.44479018,\n",
       "          0.26881033, -0.38094622],\n",
       "        [-1.8940521 , -0.80030406,  1.1014678 , ..., -0.7414971 ,\n",
       "          1.4075471 , -2.53017   ],\n",
       "        [-0.9457627 , -0.8573482 , -0.49087054, ...,  0.01483133,\n",
       "         -0.2940595 ,  0.8741598 ]],\n",
       "\n",
       "       [[ 0.03978452,  1.0761245 ,  1.0841494 , ..., -1.2231328 ,\n",
       "         -0.55342877,  1.5121046 ],\n",
       "        [-1.4462594 ,  0.3899501 ,  0.06220459, ..., -0.28765523,\n",
       "         -0.9056579 ,  1.0569195 ],\n",
       "        [-0.14841177,  0.57795256,  0.14500858, ..., -1.0352979 ,\n",
       "         -0.8812449 , -0.83084583],\n",
       "        ...,\n",
       "        [-1.7957132 , -1.304405  , -1.1450368 , ..., -0.0807131 ,\n",
       "         -1.7696592 , -0.5199275 ],\n",
       "        [-0.7329104 , -2.9593537 ,  0.66090345, ..., -0.66951716,\n",
       "         -2.3251507 , -0.32807475],\n",
       "        [ 0.39236367,  3.1788096 ,  0.49260277, ..., -2.4195807 ,\n",
       "          0.02093927,  0.09032992]]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_q = tf.random.normal((2, input_seq_len, d_model))\n",
    "input_q "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138572"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multihead_attention.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class MultiheadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiheadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "        self.num_heads = num_heads\n",
    "        self.depth = d_model // num_heads\n",
    "        \n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, q, k, v, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.split_heads(self.wq(q), batch_size)\n",
    "        k = self.split_heads(self.wk(k), batch_size)\n",
    "        v = self.split_heads(self.wv(v), batch_size)\n",
    "        print(q.shape)\n",
    "\n",
    "        scaled_attention, attention_weights = self.scaled_dot_product_attention(q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, d_model))\n",
    "\n",
    "        output = self.dense(concat_attention)\n",
    "        return output, attention_weights\n",
    "\n",
    "    def scaled_dot_product_attention(self, q, k, v, mask):\n",
    "        matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "        dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "        scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "        if mask is not None:\n",
    "            scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "        output = tf.matmul(attention_weights, v)\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 16:46:46.669389: W tensorflow/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 400.00MiB (rounded to 419430400)requested by op RandomStandardNormal\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-12-20 16:46:46.669417: I tensorflow/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2023-12-20 16:46:46.669426: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 23, Chunks in use: 23. 5.8KiB allocated for chunks. 5.8KiB in use in bin. 96B client-requested in use in bin.\n",
      "2023-12-20 16:46:46.669431: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 5, Chunks in use: 4. 3.8KiB allocated for chunks. 3.0KiB in use in bin. 2.9KiB client-requested in use in bin.\n",
      "2023-12-20 16:46:46.669436: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 15, Chunks in use: 12. 15.8KiB allocated for chunks. 12.8KiB in use in bin. 12.2KiB client-requested in use in bin.\n",
      "2023-12-20 16:46:46.669440: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 3, Chunks in use: 3. 6.0KiB allocated for chunks. 6.0KiB in use in bin. 6.0KiB client-requested in use in bin.\n",
      "2023-12-20 16:46:46.669443: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 1, Chunks in use: 1. 6.0KiB allocated for chunks. 6.0KiB in use in bin. 4.0KiB client-requested in use in bin.\n",
      "2023-12-20 16:46:46.669447: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 12, Chunks in use: 11. 148.0KiB allocated for chunks. 140.0KiB in use in bin. 130.3KiB client-requested in use in bin.\n",
      "2023-12-20 16:46:46.669451: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 5, Chunks in use: 5. 118.5KiB allocated for chunks. 118.5KiB in use in bin. 114.1KiB client-requested in use in bin.\n",
      "2023-12-20 16:46:46.669455: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 1, Chunks in use: 0. 53.0KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-20 16:46:46.669458: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 1, Chunks in use: 0. 123.5KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-20 16:46:46.669462: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 3, Chunks in use: 2. 600.0KiB allocated for chunks. 400.0KiB in use in bin. 400.0KiB client-requested in use in bin.\n",
      "2023-12-20 16:46:46.669466: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 2, Chunks in use: 2. 725.0KiB allocated for chunks. 725.0KiB in use in bin. 600.0KiB client-requested in use in bin.\n",
      "2023-12-20 16:46:46.669469: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 5, Chunks in use: 5. 2.84MiB allocated for chunks. 2.84MiB in use in bin. 2.73MiB client-requested in use in bin.\n",
      "2023-12-20 16:46:46.669473: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 5, Chunks in use: 2. 6.16MiB allocated for chunks. 2.00MiB in use in bin. 2.00MiB client-requested in use in bin.\n",
      "2023-12-20 16:46:46.669477: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 10, Chunks in use: 8. 25.00MiB allocated for chunks. 20.00MiB in use in bin. 20.00MiB client-requested in use in bin.\n",
      "2023-12-20 16:46:46.669480: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 1, Chunks in use: 0. 4.50MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-20 16:46:46.669483: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-20 16:46:46.669486: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-20 16:46:46.669490: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-20 16:46:46.669493: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 1, Chunks in use: 0. 92.17MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-20 16:46:46.669497: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-20 16:46:46.669501: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 2, Chunks in use: 2. 800.00MiB allocated for chunks. 800.00MiB in use in bin. 800.00MiB client-requested in use in bin.\n",
      "2023-12-20 16:46:46.669505: I tensorflow/tsl/framework/bfc_allocator.cc:1062] Bin for 400.00MiB was 256.00MiB, Chunk State: \n",
      "2023-12-20 16:46:46.669508: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 977731584\n",
      "2023-12-20 16:46:46.669513: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100000000 of size 1280 next 1\n",
      "2023-12-20 16:46:46.669517: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100000500 of size 256 next 2\n",
      "2023-12-20 16:46:46.669520: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100000600 of size 256 next 3\n",
      "2023-12-20 16:46:46.669523: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100000700 of size 256 next 4\n",
      "2023-12-20 16:46:46.669525: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100000800 of size 256 next 41\n",
      "2023-12-20 16:46:46.669528: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100000900 of size 256 next 44\n",
      "2023-12-20 16:46:46.669530: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100000a00 of size 256 next 11\n",
      "2023-12-20 16:46:46.669533: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f4100000b00 of size 768 next 17\n",
      "2023-12-20 16:46:46.669536: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100000e00 of size 768 next 5\n",
      "2023-12-20 16:46:46.669539: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100001100 of size 1280 next 6\n",
      "2023-12-20 16:46:46.669541: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100001600 of size 1024 next 10\n",
      "2023-12-20 16:46:46.669544: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f4100001a00 of size 1024 next 12\n",
      "2023-12-20 16:46:46.669547: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100001e00 of size 1024 next 16\n",
      "2023-12-20 16:46:46.669549: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f4100002200 of size 1024 next 19\n",
      "2023-12-20 16:46:46.669552: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100002600 of size 1024 next 20\n",
      "2023-12-20 16:46:46.669555: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100002a00 of size 12288 next 93\n",
      "2023-12-20 16:46:46.669557: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100005a00 of size 14848 next 15\n",
      "2023-12-20 16:46:46.669560: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100009400 of size 18944 next 7\n",
      "2023-12-20 16:46:46.669563: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f410000de00 of size 25600 next 8\n",
      "2023-12-20 16:46:46.669566: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100014200 of size 25600 next 9\n",
      "2023-12-20 16:46:46.669568: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f410001a600 of size 14592 next 18\n",
      "2023-12-20 16:46:46.669572: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f410001df00 of size 768 next 24\n",
      "2023-12-20 16:46:46.669575: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f410001e200 of size 256 next 31\n",
      "2023-12-20 16:46:46.669578: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f410001e300 of size 768 next 25\n",
      "2023-12-20 16:46:46.669580: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f410001e600 of size 1024 next 26\n",
      "2023-12-20 16:46:46.669583: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f410001ea00 of size 768 next 30\n",
      "2023-12-20 16:46:46.669586: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f410001ed00 of size 1024 next 46\n",
      "2023-12-20 16:46:46.669589: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f410001f100 of size 256 next 45\n",
      "2023-12-20 16:46:46.669592: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f410001f200 of size 256 next 51\n",
      "2023-12-20 16:46:46.669594: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f410001f300 of size 256 next 54\n",
      "2023-12-20 16:46:46.669597: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f410001f400 of size 256 next 52\n",
      "2023-12-20 16:46:46.669599: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f410001f500 of size 256 next 78\n",
      "2023-12-20 16:46:46.669602: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f410001f600 of size 256 next 37\n",
      "2023-12-20 16:46:46.669605: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f410001f700 of size 1280 next 38\n",
      "2023-12-20 16:46:46.669607: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f410001fc00 of size 1024 next 42\n",
      "2023-12-20 16:46:46.669610: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100020000 of size 6144 next 21\n",
      "2023-12-20 16:46:46.669613: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100021800 of size 14592 next 22\n",
      "2023-12-20 16:46:46.669615: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100025100 of size 14592 next 23\n",
      "2023-12-20 16:46:46.669618: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100028a00 of size 14592 next 27\n",
      "2023-12-20 16:46:46.669621: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f410002c300 of size 14592 next 28\n",
      "2023-12-20 16:46:46.669623: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f410002fc00 of size 14592 next 29\n",
      "2023-12-20 16:46:46.669626: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100033500 of size 8192 next 53\n",
      "2023-12-20 16:46:46.669628: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100035500 of size 8192 next 58\n",
      "2023-12-20 16:46:46.669631: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100037500 of size 1024 next 61\n",
      "2023-12-20 16:46:46.669634: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f4100037900 of size 8192 next 34\n",
      "2023-12-20 16:46:46.669636: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100039900 of size 25600 next 39\n",
      "2023-12-20 16:46:46.669639: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f410003fd00 of size 25600 next 40\n",
      "2023-12-20 16:46:46.669642: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f4100046100 of size 54272 next 83\n",
      "2023-12-20 16:46:46.669644: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100053500 of size 256 next 85\n",
      "2023-12-20 16:46:46.669647: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100053600 of size 256 next 87\n",
      "2023-12-20 16:46:46.669649: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100053700 of size 1024 next 88\n",
      "2023-12-20 16:46:46.669652: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100053b00 of size 256 next 89\n",
      "2023-12-20 16:46:46.669655: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100053c00 of size 256 next 91\n",
      "2023-12-20 16:46:46.669657: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100053d00 of size 12288 next 96\n",
      "2023-12-20 16:46:46.669660: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100056d00 of size 256 next 97\n",
      "2023-12-20 16:46:46.669662: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100056e00 of size 256 next 99\n",
      "2023-12-20 16:46:46.669665: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f4100056f00 of size 1024 next 100\n",
      "2023-12-20 16:46:46.669668: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100057300 of size 256 next 101\n",
      "2023-12-20 16:46:46.669670: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100057400 of size 256 next 103\n",
      "2023-12-20 16:46:46.669673: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100057500 of size 2048 next 104\n",
      "2023-12-20 16:46:46.669676: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100057d00 of size 2048 next 105\n",
      "2023-12-20 16:46:46.669679: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100058500 of size 2048 next 106\n",
      "2023-12-20 16:46:46.669682: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100058d00 of size 256 next 109\n",
      "2023-12-20 16:46:46.669684: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100058e00 of size 256 next 110\n",
      "2023-12-20 16:46:46.669687: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100058f00 of size 1024 next 111\n",
      "2023-12-20 16:46:46.669690: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f4100059300 of size 126464 next 47\n",
      "2023-12-20 16:46:46.669692: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100078100 of size 204800 next 43\n",
      "2023-12-20 16:46:46.669695: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f41000aa100 of size 332800 next 35\n",
      "2023-12-20 16:46:46.669698: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f41000fb500 of size 409600 next 36\n",
      "2023-12-20 16:46:46.669701: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f410015f500 of size 1741056 next 13\n",
      "2023-12-20 16:46:46.669703: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4100308600 of size 768000 next 14\n",
      "2023-12-20 16:46:46.669706: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f41003c3e00 of size 419430400 next 32\n",
      "2023-12-20 16:46:46.669710: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f41193c3e00 of size 419430400 next 33\n",
      "2023-12-20 16:46:46.669712: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f41323c3e00 of size 204800 next 79\n",
      "2023-12-20 16:46:46.669715: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f41323f5e00 of size 204800 next 77\n",
      "2023-12-20 16:46:46.669718: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4132427e00 of size 638976 next 49\n",
      "2023-12-20 16:46:46.669721: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f41324c3e00 of size 1048576 next 48\n",
      "2023-12-20 16:46:46.669723: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f41325c3e00 of size 1048576 next 50\n",
      "2023-12-20 16:46:46.669726: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f41326c3e00 of size 2097152 next 102\n",
      "2023-12-20 16:46:46.669729: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f41328c3e00 of size 524288 next 113\n",
      "2023-12-20 16:46:46.669732: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f4132943e00 of size 1572864 next 56\n",
      "2023-12-20 16:46:46.669735: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4132ac3e00 of size 2097152 next 55\n",
      "2023-12-20 16:46:46.669738: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4132cc3e00 of size 2097152 next 57\n",
      "2023-12-20 16:46:46.669740: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4132ec3e00 of size 2097152 next 59\n",
      "2023-12-20 16:46:46.669743: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f41330c3e00 of size 2097152 next 62\n",
      "2023-12-20 16:46:46.669746: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f41332c3e00 of size 3145728 next 70\n",
      "2023-12-20 16:46:46.669748: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f41335c3e00 of size 3145728 next 90\n",
      "2023-12-20 16:46:46.669751: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f41338c3e00 of size 3145728 next 86\n",
      "2023-12-20 16:46:46.669754: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4133bc3e00 of size 3145728 next 80\n",
      "2023-12-20 16:46:46.669757: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f4133ec3e00 of size 4718592 next 107\n",
      "2023-12-20 16:46:46.669759: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4134343e00 of size 524288 next 95\n",
      "2023-12-20 16:46:46.669762: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f41343c3e00 of size 1048576 next 94\n",
      "2023-12-20 16:46:46.669765: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f41344c3e00 of size 524288 next 108\n",
      "2023-12-20 16:46:46.669767: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4134543e00 of size 3145728 next 84\n",
      "2023-12-20 16:46:46.669770: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f4134843e00 of size 96649728 next 18446744073709551615\n",
      "2023-12-20 16:46:46.669773: I tensorflow/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2023-12-20 16:46:46.669777: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 23 Chunks of size 256 totalling 5.8KiB\n",
      "2023-12-20 16:46:46.669780: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 768 totalling 3.0KiB\n",
      "2023-12-20 16:46:46.669783: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 9 Chunks of size 1024 totalling 9.0KiB\n",
      "2023-12-20 16:46:46.669786: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 1280 totalling 3.8KiB\n",
      "2023-12-20 16:46:46.669789: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 2048 totalling 6.0KiB\n",
      "2023-12-20 16:46:46.669792: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 6144 totalling 6.0KiB\n",
      "2023-12-20 16:46:46.669796: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 8192 totalling 16.0KiB\n",
      "2023-12-20 16:46:46.669799: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 12288 totalling 24.0KiB\n",
      "2023-12-20 16:46:46.669802: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 14592 totalling 85.5KiB\n",
      "2023-12-20 16:46:46.669805: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 14848 totalling 14.5KiB\n",
      "2023-12-20 16:46:46.669808: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 18944 totalling 18.5KiB\n",
      "2023-12-20 16:46:46.669811: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 25600 totalling 100.0KiB\n",
      "2023-12-20 16:46:46.669814: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 204800 totalling 400.0KiB\n",
      "2023-12-20 16:46:46.669817: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 332800 totalling 325.0KiB\n",
      "2023-12-20 16:46:46.669821: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 409600 totalling 400.0KiB\n",
      "2023-12-20 16:46:46.669825: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 524288 totalling 1.50MiB\n",
      "2023-12-20 16:46:46.669828: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 638976 totalling 624.0KiB\n",
      "2023-12-20 16:46:46.669831: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 768000 totalling 750.0KiB\n",
      "2023-12-20 16:46:46.669834: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 1048576 totalling 2.00MiB\n",
      "2023-12-20 16:46:46.669837: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 2097152 totalling 8.00MiB\n",
      "2023-12-20 16:46:46.669840: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 3145728 totalling 12.00MiB\n",
      "2023-12-20 16:46:46.669843: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 419430400 totalling 800.00MiB\n",
      "2023-12-20 16:46:46.669846: I tensorflow/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 826.23MiB\n",
      "2023-12-20 16:46:46.669850: I tensorflow/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 977731584 memory_limit_: 977731584 available bytes: 0 curr_region_allocation_bytes_: 1955463168\n",
      "2023-12-20 16:46:46.669856: I tensorflow/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                       977731584\n",
      "InUse:                       866360320\n",
      "MaxInUse:                    889138688\n",
      "NumAllocs:                         333\n",
      "MaxAllocSize:                419430400\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-12-20 16:46:46.669862: W tensorflow/tsl/framework/bfc_allocator.cc:497] *******************************************************************************************_________\n",
      "2023-12-20 16:46:46.669876: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at random_op.cc:74 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[2048,200,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "pybind11::error_already_set: MISMATCH of original and normalized active exception types: ORIGINAL _NotOkStatusException REPLACED BY KeyboardInterrupt: <EMPTY MESSAGE>\n\nAt:\n  /home/yslee/.local/lib/python3.8/site-packages/tensorflow/python/eager/core.py(36): __init__\n  /home/yslee/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_random_ops.py(631): random_standard_normal\n  /home/yslee/.local/lib/python3.8/site-packages/tensorflow/python/ops/random_ops.py(91): random_normal\n  /home/yslee/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py(1176): op_dispatch_handler\n  /home/yslee/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py(150): error_handler\n  /tmp/ipykernel_237025/1858185163.py(55): <module>\n  /home/yslee/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3508): run_code\n  /home/yslee/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3448): run_ast_nodes\n  /home/yslee/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3269): run_cell_async\n  /home/yslee/.local/lib/python3.8/site-packages/IPython/core/async_helpers.py(129): _pseudo_sync_runner\n  /home/yslee/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3064): _run_cell\n  /home/yslee/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3009): run_cell\n  /home/yslee/.local/lib/python3.8/site-packages/ipykernel/zmqshell.py(549): run_cell\n  /home/yslee/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py(429): do_execute\n  /home/yslee/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py(766): execute_request\n  /home/yslee/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py(424): dispatch_shell\n  /home/yslee/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py(518): process_one\n  /home/yslee/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py(529): dispatch_queue\n  /usr/lib/python3.8/asyncio/events.py(81): _run\n  /usr/lib/python3.8/asyncio/base_events.py(1859): _run_once\n  /usr/lib/python3.8/asyncio/base_events.py(570): run_forever\n  /home/yslee/.local/lib/python3.8/site-packages/tornado/platform/asyncio.py(205): start\n  /home/yslee/.local/lib/python3.8/site-packages/ipykernel/kernelapp.py(739): start\n  /home/yslee/.local/lib/python3.8/site-packages/traitlets/config/application.py(1077): launch_instance\n  /home/yslee/.local/lib/python3.8/site-packages/ipykernel_launcher.py(17): <module>\n  /usr/lib/python3.8/runpy.py(87): _run_code\n  /usr/lib/python3.8/runpy.py(194): _run_module_as_main\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 55\u001b[0m\n\u001b[1;32m     52\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2048\u001b[39m\n\u001b[1;32m     54\u001b[0m multihead_attention \u001b[38;5;241m=\u001b[39m MultiheadAttention(d_model, num_heads)\n\u001b[0;32m---> 55\u001b[0m input_q \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_seq_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_model\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m input_k \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal((batch_size, input_seq_len, d_model))\n\u001b[1;32m     57\u001b[0m input_v \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal((batch_size, input_seq_len, d_model))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_random_ops.py:631\u001b[0m, in \u001b[0;36mrandom_standard_normal\u001b[0;34m(shape, dtype, seed, seed2, name)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m    630\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 631\u001b[0m     _result \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_FastPathExecute(\n\u001b[1;32m    632\u001b[0m       _ctx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandomStandardNormal\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, shape, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m, seed, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    633\u001b[0m       seed2, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype)\n\u001b[1;32m    634\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m    635\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: pybind11::error_already_set: MISMATCH of original and normalized active exception types: ORIGINAL _NotOkStatusException REPLACED BY KeyboardInterrupt: <EMPTY MESSAGE>\n\nAt:\n  /home/yslee/.local/lib/python3.8/site-packages/tensorflow/python/eager/core.py(36): __init__\n  /home/yslee/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_random_ops.py(631): random_standard_normal\n  /home/yslee/.local/lib/python3.8/site-packages/tensorflow/python/ops/random_ops.py(91): random_normal\n  /home/yslee/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py(1176): op_dispatch_handler\n  /home/yslee/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py(150): error_handler\n  /tmp/ipykernel_237025/1858185163.py(55): <module>\n  /home/yslee/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3508): run_code\n  /home/yslee/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3448): run_ast_nodes\n  /home/yslee/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3269): run_cell_async\n  /home/yslee/.local/lib/python3.8/site-packages/IPython/core/async_helpers.py(129): _pseudo_sync_runner\n  /home/yslee/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3064): _run_cell\n  /home/yslee/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3009): run_cell\n  /home/yslee/.local/lib/python3.8/site-packages/ipykernel/zmqshell.py(549): run_cell\n  /home/yslee/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py(429): do_execute\n  /home/yslee/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py(766): execute_request\n  /home/yslee/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py(424): dispatch_shell\n  /home/yslee/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py(518): process_one\n  /home/yslee/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py(529): dispatch_queue\n  /usr/lib/python3.8/asyncio/events.py(81): _run\n  /usr/lib/python3.8/asyncio/base_events.py(1859): _run_once\n  /usr/lib/python3.8/asyncio/base_events.py(570): run_forever\n  /home/yslee/.local/lib/python3.8/site-packages/tornado/platform/asyncio.py(205): start\n  /home/yslee/.local/lib/python3.8/site-packages/ipykernel/kernelapp.py(739): start\n  /home/yslee/.local/lib/python3.8/site-packages/traitlets/config/application.py(1077): launch_instance\n  /home/yslee/.local/lib/python3.8/site-packages/ipykernel_launcher.py(17): <module>\n  /usr/lib/python3.8/runpy.py(87): _run_code\n  /usr/lib/python3.8/runpy.py(194): _run_module_as_main\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class MultiheadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiheadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "        self.num_heads = num_heads\n",
    "        self.depth = d_model // num_heads\n",
    "        \n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, q, k, v, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.split_heads(self.wq(q), batch_size)\n",
    "        k = self.split_heads(self.wk(k), batch_size)\n",
    "        v = self.split_heads(self.wv(v), batch_size)\n",
    "        print(q.shape)\n",
    "\n",
    "        scaled_attention, attention_weights = self.scaled_dot_product_attention(q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, d_model))\n",
    "\n",
    "        output = self.dense(concat_attention)\n",
    "        return output, attention_weights\n",
    "\n",
    "    def scaled_dot_product_attention(self, q, k, v, mask):\n",
    "        matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "        dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "        scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "        if mask is not None:\n",
    "            scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "        output = tf.matmul(attention_weights, v)\n",
    "        return output, attention_weights\n",
    "\n",
    "# \n",
    "d_model = 256\n",
    "num_heads = 8\n",
    "input_seq_len = 200\n",
    "batch_size = 2048\n",
    "\n",
    "multihead_attention = MultiheadAttention(d_model, num_heads)\n",
    "input_q = tf.random.normal((batch_size, input_seq_len, d_model))\n",
    "input_k = tf.random.normal((batch_size, input_seq_len, d_model))\n",
    "input_v = tf.random.normal((batch_size, input_seq_len, d_model))\n",
    "mask = None  # Optional mask to specify which positions should be masked\n",
    "\n",
    "output, attention_weights = multihead_attention(input_q, input_k, input_v, mask)\n",
    "print(\"Multihead Attention Output shape:\", output.shape)\n",
    "print(\"Attention Weights shape:\", attention_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'multihead_attention_16/dense_64/bias:0' shape=(256,) dtype=float32, numpy=\n",
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0.], dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multihead_attention.trainable_variables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263168"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multihead_attention.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
